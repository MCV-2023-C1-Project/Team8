{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C1 - Content Based Image Retrieval\n",
    "### Team 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    def get_mask(self, img, mode, threshold_area=71000):\n",
    "        \n",
    "        if mode == 'rgb':\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        elif mode == 'hsv':\n",
    "            gray = img[:,:,2].copy()\n",
    "        else:\n",
    "            gray = img[:,:,0].copy()\n",
    "        blur = cv2.GaussianBlur(gray, (13,13), 0)\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2) # threshold based on local pixel neighborhood (11x11 block size)\n",
    "\n",
    "        # Two pass dilate with horizontal and vertical kernel\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\n",
    "        dilate = cv2.dilate(thresh, horizontal_kernel, iterations=2)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\n",
    "        dilate = cv2.dilate(dilate, vertical_kernel, iterations=2)\n",
    "\n",
    "        # Find contours, filter using contour threshold area, and draw rectangle\n",
    "        cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        '''\n",
    "        cv2.RETR_EXTERNAL retrieves only the extreme outer contours.\n",
    "        cv2.CHAIN_APPROX_SIMPLE compresses horizontal, vertical, and diagonal segments and leaves only their end points.\n",
    "        Follows Satoshi Suzuki's algorithm:\n",
    "            1- The algorithm works by border following, which means it traces the boundary of connected components in the image.\n",
    "            2- It starts from the top-left corner of the image and looks for the first white pixel. Once found, it begins to follow the contour border.\n",
    "            3- While following the contour, the algorithm keeps track of the direction in which it is moving to ensure it stays on the boundary.\n",
    "            4- Once the entire contour is followed and the start point is reached again, the algorithm continues scanning the image for the next contour.\n",
    "        '''\n",
    "\n",
    "        mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "        counter = 0\n",
    "        areas = []\n",
    "        coordinates = []\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c) # shoelace formula for convex shapes\n",
    "            if area > threshold_area:\n",
    "                x,y,w,h = cv2.boundingRect(c) # get bounding box\n",
    "                areas.append((area, (x,y,w,h)))\n",
    "                counter += 1\n",
    "\n",
    "        # Sort areas and positions by area\n",
    "        areas = sorted(areas, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        for i in range(min(len(areas), 2)):\n",
    "            x,y,w,h = areas[i][1]\n",
    "            coordinates.append((x,y,w,h))\n",
    "            mask[y:y+h, x:x+w] = 255 # draw bounding box on mask\n",
    "\n",
    "                # counter += 1\n",
    "                # if counter > 2:\n",
    "                #     print('Error! Too many paintings in this image!')\n",
    "                #     plt.imshow(img)\n",
    "                #     plt.show()\n",
    "                #     plt.imshow(mask, cmap='gray')\n",
    "                #     plt.show()\n",
    "\n",
    "        if counter == 0:\n",
    "            print('Error! No paintings in this image!')\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            plt.imshow(mask, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        return mask, coordinates\n",
    "    \n",
    "    def get_mask_text(self, img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "        opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        x = closing-opening\n",
    "        x = (x>150).astype(np.uint8)\n",
    "\n",
    "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (13,13))\n",
    "        dilated = cv2.dilate(x, kernel2, iterations=2)\n",
    "\n",
    "        ctns = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        areas = []\n",
    "        for c in ctns[0]:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if w > h:\n",
    "                areas.append((cv2.contourArea(c), (x,y,w,h)))\n",
    "\n",
    "\n",
    "        areas = sorted(areas, key=lambda x: x[0], reverse=True)\n",
    "        x, y, w, h = areas[0][1]\n",
    "\n",
    "        for _, shape in areas:\n",
    "            if y > shape[1]-10 and y < shape[1]+10:\n",
    "                if shape[0] < x:\n",
    "                    w = (x+w) - shape[0]\n",
    "                    x = shape[0]\n",
    "                else:\n",
    "                    w = (shape[0]+shape[2]) - x\n",
    "        \n",
    "        return [x,y,x+w,y+h]\n",
    "\n",
    "    def create_blocks_array(self, image, blockNumber):\n",
    "    \n",
    "        # Set number of slices per axis\n",
    "        axisSlice = int(math.sqrt(blockNumber))\n",
    "\n",
    "        blocksArray = []\n",
    "        # Split the image into vertical blocks\n",
    "        split_h = np.array_split(image, axisSlice, axis = 0)\n",
    "        \n",
    "        for i in range(axisSlice):\n",
    "            for j in range(axisSlice):\n",
    "                # Split vertical blocks into square blocks\n",
    "                split_hv = np.array_split(split_h[i], axisSlice, axis = 1)\n",
    "                blocksArray.append(split_hv[j])\n",
    "        return blocksArray\n",
    "\n",
    "    def create_histogram(self, block, mask, d_hist, mode, bins):\n",
    "        channels = cv2.split(block)\n",
    "\n",
    "        if mode == 'lab' and d_hist < 3: channels = channels[1:]\n",
    "        \n",
    "        range_a, range_b = 256, 256\n",
    "        if mode == 'hsv': range_a = 180\n",
    "\n",
    "        if d_hist == 1:\n",
    "            if mask is None:\n",
    "                # Compute 1D histograms for each channel separately\n",
    "                hist = [cv2.calcHist([chan], [0], None, [bins], [0, range_a if i == 0 else range_b]) for i,chan in enumerate(channels)]\n",
    "            else:\n",
    "                # Compute 1D histograms for each channel separately\n",
    "                hist = [cv2.calcHist([chan[mask!=0]], [0], None, [bins], [0, range_a if i == 0 else range_b]) for i,chan in enumerate(channels)]\n",
    "\n",
    "        elif d_hist == 2:\n",
    "            if mask is None:\n",
    "                # Compute 2D joint histograms for each pair of channels\n",
    "                hist = [cv2.calcHist([channels[i], channels[j]], [0, 1], None, [bins, bins], [0, range_a if i == 0 else range_b, 0, range_b])\n",
    "                            for i in range(len(channels)) for j in range(i+1, len(channels))]\n",
    "            else:\n",
    "                # Compute 2D joint histograms for each pair of channels\n",
    "                hist = [cv2.calcHist([channels[i][mask!=0], channels[j][mask!=0]], [0, 1], None, [bins, bins], [0, range_a if i == 0 else range_b, 0, range_b])\n",
    "                            for i in range(len(channels)) for j in range(i+1, len(channels))]\n",
    "\n",
    "        else:\n",
    "            if mask is None:\n",
    "                # Compute 3D joint histogram for all three channels\n",
    "                hist, _ = np.histogramdd([c.flatten() for c in channels], bins=(bins, bins, bins), range=[(0, range_a), (0, range_b), (0, range_b)])\n",
    "            else:\n",
    "                # Compute 3D joint histogram for all three channels\n",
    "                hist, _ = np.histogramdd([c[mask != 0] for c in channels], bins=(bins, bins, bins), range=[(0, range_a), (0, range_b), (0, range_b)])\n",
    "\n",
    "        return hist\n",
    "    \n",
    "    def get_features_by_blocks(self, image, level, mode, d_hist, bins, mask_text=None):\n",
    "\n",
    "        # Get blocks using multi-level resolution\n",
    "        blocksArray = []\n",
    "        for lvl in range(level+1):\n",
    "            for b in self.create_blocks_array(image, (2**lvl)*(2**lvl)):\n",
    "                blocksArray.append(b)\n",
    "\n",
    "        histograms = []\n",
    "        # if mask is not None:\n",
    "        #     if mask_text is not None:\n",
    "        #         mask[mask_text[1]:mask_text[3], mask_text[0]:mask_text[2]] = 0\n",
    "\n",
    "        #     blocksMasks = []\n",
    "        #     for lvl in range(level+1):\n",
    "        #         for b in self.create_blocks_array(mask, (2**lvl)*(2**lvl)):\n",
    "        #             blocksMasks.append(b) \n",
    "            \n",
    "        #     for block, mask_i in zip(blocksArray, blocksMasks):\n",
    "        #         # Compute the histogram of the channel and append it to the list\n",
    "        #         hist = self.create_histogram(block, mask_i, d_hist, mode, bins)\n",
    "        #         if isinstance(hist, list):\n",
    "        #             for h in hist:\n",
    "        #                 histograms.append(h.flatten() / (block.shape[0]*block.shape[1]))\n",
    "        #         else:\n",
    "        #             histograms.append(hist.flatten() / (block.shape[0]*block.shape[1]))\n",
    "        \n",
    "        # else:\n",
    "        for block in blocksArray:\n",
    "            # Compute the histogram of the channel and append it to the list\n",
    "            hist = self.create_histogram(block, None, d_hist, mode, bins)\n",
    "            if isinstance(hist, list):\n",
    "                for h in hist:\n",
    "                    histograms.append(h.flatten() / (block.shape[0]*block.shape[1]))\n",
    "            else:\n",
    "                histograms.append(hist.flatten()  / (block.shape[0]*block.shape[1]))\n",
    "            \n",
    "        # Concatenate all histograms into a single feature vector\n",
    "        return np.concatenate(histograms)\n",
    "    \n",
    "    def load_data(self, level = 3, d_hist = 1, bins = 64, remove_background=False, remove_text=False):\n",
    "        # Get a list of all image file names in the folder\n",
    "        image_files = glob.glob(self.folder_path+'/*.jpg')\n",
    "\n",
    "        # Initialize an empty list to store the processed images and masks\n",
    "        processed_features_rgb = dict()\n",
    "        processed_features_hsv = dict()\n",
    "        processed_features_lab = dict()\n",
    "        masks, masks_text = [], []\n",
    "\n",
    "        # Iterate over each image file\n",
    "        for f in tqdm.tqdm(image_files):\n",
    "\n",
    "            img_id = int(f.split('\\\\')[-1].split('.')[0].split('_')[-1])\n",
    "\n",
    "            # Load the image\n",
    "            image = cv2.imread(f)\n",
    "            # Convert the image from BGR to lab color space\n",
    "            image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "            # Convert the image from BGR to HSV color space\n",
    "            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Remove background (it can be 2 paintings in the same image)\n",
    "            if remove_background:\n",
    "                mask_image, coordinates = self.get_mask(image, 'rgb')\n",
    "               \n",
    "                if remove_text:\n",
    "                    coordinates = sorted(coordinates, key=lambda x: (x[0], x[1]))\n",
    "                    masks_text_i = [[None]]*len(coordinates)\n",
    "                    for i, (x,y,w,h) in enumerate(coordinates):\n",
    "                        x_text, y_text, w_text, h_text = self.get_mask_text(image[y:y+h, x:x+w])\n",
    "                        masks_text_i[i] = [x+x_text, y+y_text, x+x_text+w_text, y+y_text+h_text]\n",
    "                    masks_text.append(masks_text_i)\n",
    "                else:\n",
    "                    for i in range(len(coordinates)):\n",
    "                        masks_text.append([None])\n",
    "\n",
    "            else:\n",
    "                mask_image = None\n",
    "\n",
    "                coordinates = [[0,0,image.shape[1],image.shape[0]]]\n",
    "                if remove_text:\n",
    "                    masks_text.append([self.get_mask_text(image)])\n",
    "                else:\n",
    "                    masks_text.append([None])\n",
    "\n",
    "            masks.append(mask_image)\n",
    "            \n",
    "            features, features_hsv, features_lab = [], [], []\n",
    "            for i in range(len(coordinates)):\n",
    "                x,y,w,h = coordinates[i]\n",
    "\n",
    "                relative_mask_text = None\n",
    "                if masks_text[-1][i] is not None:\n",
    "                    relative_mask_text = [masks_text[-1][i][0]-x, masks_text[-1][i][1]-y, masks_text[-1][i][2]-x, masks_text[-1][i][3]-y]\n",
    "\n",
    "                # Get the features of the image\n",
    "                f = self.get_features_by_blocks(image[y:y+h, x:x+w], level, 'rgb', d_hist, bins, mask_text=relative_mask_text)\n",
    "                f_hsv = self.get_features_by_blocks(image_hsv[y:y+h, x:x+w], level, 'hsv', d_hist, bins, mask_text=relative_mask_text)\n",
    "                f_lab = self.get_features_by_blocks(image_lab[y:y+h, x:x+w], level, 'lab', d_hist, bins, mask_text=relative_mask_text)\n",
    "\n",
    "                features.append(f)\n",
    "                features_hsv.append(f_hsv)\n",
    "                features_lab.append(f_lab)\n",
    "\n",
    "            # Append the features to the dict\n",
    "            processed_features_rgb[img_id] = features\n",
    "            processed_features_hsv[img_id] = features_hsv\n",
    "            processed_features_lab[img_id] = features_lab\n",
    "\n",
    "        return processed_features_rgb, processed_features_hsv, processed_features_lab, masks, masks_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/benhamner/Metrics -> Metrics.Python.ml_metrics.average_precision.py\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "# Copied from https://github.com/benhamner/Metrics -> Metrics.Python.ml_metrics.average_precision.py\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for a,p in zip(actual, predicted):\n",
    "        for a_i, p_i in zip(a,p):\n",
    "            result.append(apk([a_i],p_i,k))\n",
    "    return np.mean(result)\n",
    "\n",
    "# compute the histogram intersection between two feature vectors\n",
    "def histogram_intersection(hist1, hist2):\n",
    "    return np.sum(np.minimum(hist1, hist2))\n",
    "\n",
    "# compute the euclidian distance between two feature vectors\n",
    "def euclidian_distance(hist1, hist2):\n",
    "    return np.sqrt(np.sum(np.square(hist1 - hist2)))\n",
    "\n",
    "# compute the chi-squared distance between two feature vectors\n",
    "def chi_squared_distance(hist1, hist2):\n",
    "    return np.sum(np.square(hist1 - hist2) / (hist1 + hist2 + 1e-10))\n",
    "\n",
    "# compute the bhattacharyya distance between two feature vectors\n",
    "def bhattacharyya_distance(hist1, hist2):\n",
    "    # Ensure that both histograms have the same shape\n",
    "    assert hist1.shape == hist2.shape, \"Histograms must have the same shape\"\n",
    "    # Calculate the Bhattacharyya coefficient\n",
    "    bhattacharyya_coeff = np.sum(np.sqrt(hist1 * hist2))\n",
    "    # Calculate the Bhattacharyya distance\n",
    "    bhattacharyya_distance = -np.log(bhattacharyya_coeff)\n",
    "    return bhattacharyya_distance\n",
    "\n",
    "# compute the Helling distance (Hellinger kernel) between two feature vectors\n",
    "def hellinger_kernel(hist1, hist2):\n",
    "    return np.sum(np.sqrt(hist1*hist2))\n",
    "\n",
    "def compare_images(query_features, bbdd_features, k, sim_func):\n",
    "    result = []\n",
    "    for id1,f1 in query_features.items():\n",
    "        result_i = []\n",
    "        for i,f_i in enumerate(f1):\n",
    "            distances = []\n",
    "            for id2,f2 in bbdd_features.items():\n",
    "                distances.append((id2, sim_func(f_i,f2)))\n",
    "                #get k smallest values from distances\n",
    "            \n",
    "            if sim_func in [euclidian_distance, chi_squared_distance, bhattacharyya_distance]:\n",
    "                k_smallest = sorted(distances, reverse=False, key=lambda x: x[1])[:k]\n",
    "            else:\n",
    "                k_smallest = sorted(distances, reverse=True, key=lambda x: x[1])[:k]\n",
    "            result_i.append((id1, k_smallest))\n",
    "            \n",
    "        result.append(result_i)\n",
    "        \n",
    "    result2 = []\n",
    "    for x in result:\n",
    "        result2_i = []\n",
    "        for y in x:\n",
    "            result2_i.append([z[0] for z in y[1]])\n",
    "        result2.append(result2_i)\n",
    "    \n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_accumulation_pixel(pixel_candidates, pixel_annotation):\n",
    "    \"\"\" \n",
    "    performance_accumulation_pixel()\n",
    "\n",
    "    Function to compute different performance indicators \n",
    "    (True Positive, False Positive, False Negative, True Negative) \n",
    "    at the pixel level\n",
    "       \n",
    "    [pixelTP, pixelFP, pixelFN, pixelTN] = performance_accumulation_pixel(pixel_candidates, pixel_annotation)\n",
    "       \n",
    "    Parameter name      Value\n",
    "    --------------      -----\n",
    "    'pixel_candidates'   Binary image marking the foreground areas\n",
    "    'pixel_annotation'   Binary image containing ground truth\n",
    "       \n",
    "    The function returns the number of True Positive (pixelTP), False Positive (pixelFP), \n",
    "    False Negative (pixelFN) and True Negative (pixelTN) pixels in the image pixel_candidates\n",
    "    \"\"\"\n",
    "    \n",
    "    pixel_candidates = np.uint64(pixel_candidates>0)\n",
    "    pixel_annotation = np.uint64(pixel_annotation>0)\n",
    "    \n",
    "    pixelTP = np.sum(pixel_candidates & pixel_annotation)\n",
    "    pixelFP = np.sum(pixel_candidates & (pixel_annotation==0))\n",
    "    pixelFN = np.sum((pixel_candidates==0) & pixel_annotation)\n",
    "    pixelTN = np.sum((pixel_candidates==0) & (pixel_annotation==0))\n",
    "\n",
    "\n",
    "    return [pixelTP, pixelFP, pixelFN, pixelTN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load ground truth files for each query\n",
    "with open('C:/Users/Luis/Documents/Universidad/MCV/C1/Lab2/data/qsd2_w1/gt_corresps.pkl', 'rb') as f:\n",
    "    gt_w1 = pickle.load(f)\n",
    "\n",
    "with open('C:/Users/Luis/Documents/Universidad/MCV/C1/Lab2/data/qsd1_w2/gt_corresps.pkl', 'rb') as f:\n",
    "    gt_w2_1 = pickle.load(f)\n",
    "\n",
    "with open('C:/Users/Luis/Documents/Universidad/MCV/C1/Lab2/data/qsd2_w2/gt_corresps.pkl', 'rb') as f:\n",
    "    gt_w2_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation results\n",
    "\n",
    "### Method 1:\n",
    "- Represent the original image in the HSV color space.\n",
    "- Image descriptor: Concatenate the normalised histograms of the 3 image channels.\n",
    "- Chi-square distance as the similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/287 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:41<00:00,  6.99it/s]\n",
      "100%|██████████| 30/30 [00:04<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins: 48, Level: 0, D_hist: 1, mAP@1: 0.36666666666666664\n",
      "Bins: 48, Level: 0, D_hist: 1, mAP@1: 0.4\n",
      "Bins: 48, Level: 0, D_hist: 1, mAP@1: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:43<00:00,  6.52it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins: 48, Level: 0, D_hist: 2, mAP@1: 0.43333333333333335\n",
      "Bins: 48, Level: 0, D_hist: 2, mAP@1: 0.4666666666666667\n",
      "Bins: 48, Level: 0, D_hist: 2, mAP@1: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [06:18<00:00,  1.32s/it]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins: 48, Level: 0, D_hist: 3, mAP@1: 0.43333333333333335\n",
      "Bins: 48, Level: 0, D_hist: 3, mAP@1: 0.43333333333333335\n",
      "Bins: 48, Level: 0, D_hist: 3, mAP@1: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [01:31<00:00,  3.12it/s]\n",
      "100%|██████████| 30/30 [00:04<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins: 48, Level: 2, D_hist: 1, mAP@1: 0.6\n",
      "Bins: 48, Level: 2, D_hist: 1, mAP@1: 0.6\n",
      "Bins: 48, Level: 2, D_hist: 1, mAP@1: 0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 271/287 [01:39<00:02,  7.10it/s]"
     ]
    }
   ],
   "source": [
    "# Retrieval parameters\n",
    "k = 1\n",
    "sim_func = chi_squared_distance\n",
    "\n",
    "for bins in [48]:\n",
    "    for lvl in [0,2,4]:\n",
    "        for d_hist in [1,2,3]:\n",
    "            if lvl == 4 and d_hist == 3: continue\n",
    "            # Create DataLoader objects for both the database and the queries\n",
    "            data_loader = DataLoader('C:/Users/Luis/Documents/Universidad/MCV/C1/Lab2/data/BBDD')\n",
    "            features_rgb, features_hsv, features_lab, _, _ = data_loader.load_data(remove_background=False, level=lvl, d_hist=d_hist, bins=bins)\n",
    "\n",
    "            data_loader_q2 = DataLoader('data/qsd2_w1')\n",
    "            features_rgb_q2_w1, features_hsv_q2_w1, features_lab_q2_w1, masks, masks_text = data_loader_q2.load_data(remove_background=True, remove_text=False, level=lvl, d_hist=d_hist, bins=bins)\n",
    "\n",
    "            # Query 1: Results and mAP@k\n",
    "            results_rgb_q1 = compare_images(features_rgb_q2_w1, features_rgb, k, sim_func)\n",
    "            results_hsv_q1 = compare_images(features_hsv_q2_w1, features_hsv, k, sim_func)\n",
    "            results_lab_q1 = compare_images(features_lab_q2_w1, features_lab, k, sim_func)\n",
    "            \n",
    "            mapk_rgb_1 = mapk(gt_w1, results_rgb_q1, 1)\n",
    "            # mapk_rgb_5 = mapk(gt_w1, results_rgb_q1, 5)\n",
    "\n",
    "            print(f'Bins: {bins}, Level: {lvl}, D_hist: {d_hist}, mAP@1: {mapk_rgb_1}')#, mAP@5: {mapk_rgb_5}')\n",
    "\n",
    "            mapk_hsv_1 = mapk(gt_w1, results_hsv_q1, 1)\n",
    "            # mapk_hsv_5 = mapk(gt_w1, results_hsv_q1, 5)\n",
    "\n",
    "            print(f'Bins: {bins}, Level: {lvl}, D_hist: {d_hist}, mAP@1: {mapk_hsv_1}')#, mAP@5: {mapk_rgb_5}')\n",
    "\n",
    "            mapk_lab_1 = mapk(gt_w1, results_lab_q1, 1)\n",
    "            # mapk_lab_5 = mapk(gt_w1, results_lab_q1, 5)\n",
    "\n",
    "            print(f'Bins: {bins}, Level: {lvl}, D_hist: {d_hist}, mAP@1: {mapk_lab_1}')#, mAP@5: {mapk_rgb_5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load ground truth files for each query\n",
    "with open('data/qsd2_w2/text_boxes.pkl', 'rb') as f:\n",
    "    boxes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Results and mAP@k\n",
    "results_hsv_q2 = compare_images(features_hsv_q2, features_hsv, k, sim_func)\n",
    "\n",
    "mapk_lab_1 = mapk(gt2, results_hsv_q2, 1)\n",
    "mapk_lab_5 = mapk(gt2, results_hsv_q2, 5)\n",
    "mapk_lab_10 = mapk(gt2, results_hsv_q2, 10)\n",
    "\n",
    "mapk_lab_1, mapk_lab_5, mapk_lab_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2, removing background: Results and mAP@k\n",
    "results_hsv_q2_no_back = compare_images(features_hsv_q2_no_back, features_hsv, k, sim_func)\n",
    "\n",
    "mapk_lab_1 = mapk(gt2, results_hsv_q2_no_back, 1)\n",
    "mapk_lab_5 = mapk(gt2, results_hsv_q2_no_back, 5)\n",
    "mapk_lab_10 = mapk(gt2, results_hsv_q2_no_back, 10)\n",
    "\n",
    "mapk_lab_1, mapk_lab_5, mapk_lab_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2:\n",
    "- Represent the original image in the CIE Lab color space.\n",
    "- Image descriptor: Divide the image in 256 blocks, get the histogram for each one and concatenate all of them.\n",
    "- Histogram intersection as the similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval parameters\n",
    "k = 10\n",
    "sim_func = histogram_intersection\n",
    "\n",
    "# Create DataLoader objects for both the database and the queries\n",
    "data_loader = DataLoader('BBDD')\n",
    "_, _, features_lab, _ = data_loader.load_data(blocks=True, blockNumber=4)\n",
    "\n",
    "data_loader_q1 = DataLoader('qsd1_w1')\n",
    "_, _, features_lab_q1, _ = data_loader_q1.load_data(blocks=True, blockNumber=4)\n",
    "\n",
    "data_loader_q2 = DataLoader('qsd2_w1')\n",
    "# _, _, features_lab_q2, _ = data_loader_q2.load_data(blocks=True, blockNumber=256)\n",
    "_, _, features_lab_q2_no_back, masks = data_loader_q2.load_data(blocks=True, blockNumber=4, remove_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Results and mAP@k\n",
    "results_lab_q1 = compare_images(features_lab_q1, features_lab, k, sim_func)\n",
    "\n",
    "mapk_lab_1 = mapk(gt1, results_lab_q1, 1)\n",
    "mapk_lab_5 = mapk(gt1, results_lab_q1, 5)\n",
    "mapk_lab_10 = mapk(gt1, results_lab_q1, 10)\n",
    "\n",
    "mapk_lab_1, mapk_lab_5, mapk_lab_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Results and mAP@k\n",
    "results_lab_q2 = compare_images(features_lab_q2, features_lab, k, sim_func)\n",
    "\n",
    "mapk_lab_1 = mapk(gt2, results_lab_q1, 1)\n",
    "mapk_lab_5 = mapk(gt2, results_lab_q1, 5)\n",
    "mapk_lab_10 = mapk(gt2, results_lab_q1, 10)\n",
    "\n",
    "mapk_lab_1, mapk_lab_5, mapk_lab_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2, removing background: Results and mAP@k\n",
    "results_lab_q2_no_back = compare_images(features_lab_q2_no_back, features_lab, k, sim_func)\n",
    "\n",
    "mapk_lab_1 = mapk(gt2, results_lab_q2_no_back, 1)\n",
    "mapk_lab_5 = mapk(gt2, results_lab_q2_no_back, 5)\n",
    "mapk_lab_10 = mapk(gt2, results_lab_q2_no_back, 10)\n",
    "\n",
    "mapk_lab_1, mapk_lab_5, mapk_lab_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and F1-score of the masking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/qsd2_w1\"\n",
    "\n",
    "precision, recall, f1 = [], [], []\n",
    "for i, im_file in enumerate(glob.glob(os.path.join(folder_path, \"*.png\"))):\n",
    "    mask_gt = cv2.imread(im_file, cv2.IMREAD_GRAYSCALE)\n",
    "    pixelTP, pixelFP, pixelFN, pixelTN = performance_accumulation_pixel(masks_q[i][1], mask_gt)\n",
    "\n",
    "    p = pixelTP / (pixelTP + pixelFP)\n",
    "    r = pixelTP / (pixelTP + pixelFN)\n",
    "\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    f1.append(2 * (p * r) / (p + r))\n",
    "\n",
    "print(\"Precision:\", np.mean(precision))\n",
    "print(\"Recall:\", np.mean(recall))\n",
    "print(\"F1-score:\", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    ax[i,0].imshow(masks_q[i][0], cmap='gray')\n",
    "    ax[i,1].imshow(masks_q[i][1], cmap='gray')\n",
    "    ax[i,2].imshow(masks_q[i][2], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test results from both queries\n",
    "\n",
    "#### Method 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for both the database and the queries\n",
    "data_loader = DataLoader('data/BBDD')\n",
    "_, features_hsv, _, _ = data_loader.load_data(blocks=False)\n",
    "\n",
    "data_loader_q1 = DataLoader('data/qst1_w1')\n",
    "_, features_hsv_q1, _, _ = data_loader_q1.load_data(blocks=False)\n",
    "\n",
    "data_loader_q2_no_back = DataLoader('data/qst2_w1')\n",
    "_, features_hsv_q2_no_back, _, masks = data_loader_q2_no_back.load_data(blocks=False, remove_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval parameters\n",
    "k = 10\n",
    "sim_func = chi_squared_distance\n",
    "\n",
    "# Get results\n",
    "results_hsv_q1 = compare_images(features_hsv_q1, features_hsv, k, sim_func)\n",
    "results_hsv_q2_no_back = compare_images(features_hsv_q2_no_back, features_hsv, k, sim_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as pickle files and masks as png images\n",
    "with open(\"test_results/QST1/method1/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_hsv_q1, f)\n",
    "\n",
    "with open(\"test_results/QST2/method1/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_hsv_q2_no_back, f)\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    final_mask = (mask[0]*mask[1]*mask[2])*255\n",
    "    image_mask_name = str(i).zfill(5) + \".png\"\n",
    "    cv2.imwrite(os.path.join(\"test_results/QST2/method1/\", image_mask_name), final_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for both the database and the queries\n",
    "data_loader = DataLoader('data/BBDD')\n",
    "_, _, features_lab, _ = data_loader.load_data(blocks=True, blockNumber=256)\n",
    "\n",
    "data_loader_q1 = DataLoader('data/qst1_w1')\n",
    "_, _, features_lab_q1, _ = data_loader_q1.load_data(blocks=True, blockNumber=256)\n",
    "\n",
    "data_loader_q2_no_back = DataLoader('data/qst2_w1')\n",
    "_, _, features_lab_q2_no_back, masks = data_loader_q2_no_back.load_data(blocks=True, blockNumber=256, remove_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval parameters\n",
    "k = 10\n",
    "sim_func = histogram_intersection\n",
    "\n",
    "# Get results\n",
    "results_lab_q1 = compare_images(features_lab_q1, features_lab, k, sim_func)\n",
    "results_lab_q2_no_back = compare_images(features_lab_q2_no_back, features_lab, k, sim_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result lists as pickle files and masks as png images\n",
    "with open(\"test_results/QST1/method2/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_lab_q1, f)\n",
    "\n",
    "with open(\"test_results/QST2/method2/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_lab_q2_no_back, f)\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    final_mask = (mask[0]*mask[1]*mask[2])*255\n",
    "    image_mask_name = str(i).zfill(5) + \".png\"\n",
    "    cv2.imwrite(os.path.join(\"test_results/QST2/method2/\", image_mask_name), final_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
